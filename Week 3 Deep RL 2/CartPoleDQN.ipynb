{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CartPoleDQN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuhammadAliAhsan/Ahsan_MLProject/blob/main/Week%203%20Deep%20RL%202/CartPoleDQN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKK5DA390wRe"
      },
      "source": [
        "# Deep Q Network (DQN) for CartPole Using Boltzmann Q Policy\n",
        "This exercise implements a DQN for CartPole using a Boltzmann Q policy for selecting the actions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGsC7cJ5jNcX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "928043b4-e550-40f0-fc48-545ffa3acde0"
      },
      "source": [
        "# install keras rl2 (we need to install keras-rl2 so it works with the tensorflow 2 version that comes pre-installed with colab)\n",
        "!pip install keras-rl2"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-rl2 in /usr/local/lib/python3.7/dist-packages (1.0.5)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from keras-rl2) (2.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.10.0.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.24.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.14.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.1.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.5.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (13.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.44.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.8.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.6.3)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.17.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (57.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.21.5)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->keras-rl2) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->keras-rl2) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (3.3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMIHLgQ3Z-lF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fd3a7c4-f9af-4f4d-deb6-1f7faa44c2a6"
      },
      "source": [
        "!pip install gym"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.21.5)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0AMLzq08ap0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a9f06dd-fd9f-4c9c-90b1-39cde93eeffc"
      },
      "source": [
        "# load the gym module\n",
        "import gym\n",
        "import matplotlib.pyplot as plt\n",
        "# import the usual Keras modules for creating deep neural networks\n",
        "from keras import Sequential\n",
        "from keras.layers import Input, Flatten, Dense\n",
        "!pip install Adam\n",
        "#from keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "ENV_NAME = 'CartPole-v0'\n",
        "env = gym.make(ENV_NAME)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Adam in /usr/local/lib/python3.7/dist-packages (0.0.0.dev0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ll6bNdUm54WS"
      },
      "source": [
        "Implementation of DQN for CartPole, applying policy BoltzmannQPolicy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSCrPKNy40PC"
      },
      "source": [
        "##Implement DQN with BoltzmannGumbelQPolicy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efM9jkXr5A3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "baf215a2-2653-4206-c429-c8f3be078138"
      },
      "source": [
        "import rl\n",
        "from rl.memory import SequentialMemory  # import the exerience replay buffer module\n",
        "from rl.policy import BoltzmannGumbelQPolicy\n",
        "from rl.policy import LinearAnnealedPolicy\n",
        "from rl.policy import EpsGreedyQPolicy\n",
        "from rl.agents.dqn import DQNAgent      # import the DQN agent\n",
        "\n",
        "# setup experience replay buffer\n",
        "memory = SequentialMemory(limit=10000, window_length=1)\n",
        "\n",
        "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), \n",
        "                               attr='eps',            \n",
        "                               value_max=1.,\n",
        "                               value_min=.1, \n",
        "                               value_test=.05,\n",
        "                               nb_steps=200)\n",
        "# Q-Network\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(1,env.observation_space.shape[0])))  # The input is 1 observation vector, and the number of observations in that vector \n",
        "model.add(Flatten())\n",
        "model.add(Dense(16, activation='relu'))\n",
        "# add extra layers here\n",
        "model.add(Dense(env.action_space.n, activation='linear'))   # the output is the number of actions in the action space\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "# define the agent\n",
        "dqn = DQNAgent(model=model, \n",
        "               nb_actions=env.action_space.n,\n",
        "               memory=memory,\n",
        "               nb_steps_warmup=7,\n",
        "               target_model_update=1e-2, \n",
        "               policy=policy) \n",
        "\n",
        "dqn.compile(Adam(lr=1e-1), metrics=['mae'])\n",
        "\n",
        "history = dqn.fit(env, nb_steps=9000, visualize=False, verbose=2)\n",
        "\n",
        "# summarize the history for number  of episode steps\n",
        "plt.plot(history.history['nb_episode_steps'])\n",
        "plt.ylabel('nb_episode_steps')\n",
        "plt.xlabel('episodes')\n",
        "plt.show()\n",
        "\n",
        "dqn.test(env, nb_episodes=20, visualize=False)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_25 (Flatten)        (None, 4)                 0         \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 16)                80        \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 2)                 34        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 9000 steps ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n",
            "/usr/local/lib/python3.7/dist-packages/rl/memory.py:37: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
            "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   16/9000: episode: 1, duration: 5.672s, episode steps:  16, steps per second:   3, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.562 [0.000, 1.000],  loss: 0.156592, mae: 0.759441, mean_q: 1.370492, mean_eps: 0.948250\n",
            "   28/9000: episode: 2, duration: 0.126s, episode steps:  12, steps per second:  95, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.750 [0.000, 1.000],  loss: 0.020351, mae: 0.750118, mean_q: 1.509693, mean_eps: 0.903250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/rl/memory.py:37: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
            "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n",
            "/usr/local/lib/python3.7/dist-packages/rl/memory.py:37: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
            "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   42/9000: episode: 3, duration: 0.154s, episode steps:  14, steps per second:  91, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.643 [0.000, 1.000],  loss: 0.014686, mae: 0.799927, mean_q: 1.678303, mean_eps: 0.844750\n",
            "   65/9000: episode: 4, duration: 0.235s, episode steps:  23, steps per second:  98, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.565 [0.000, 1.000],  loss: 0.020375, mae: 0.887818, mean_q: 1.791119, mean_eps: 0.761500\n",
            "   76/9000: episode: 5, duration: 0.116s, episode steps:  11, steps per second:  94, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.818 [0.000, 1.000],  loss: 0.022722, mae: 0.969766, mean_q: 1.906252, mean_eps: 0.685000\n",
            "   89/9000: episode: 6, duration: 0.147s, episode steps:  13, steps per second:  89, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.692 [0.000, 1.000],  loss: 0.036467, mae: 1.018793, mean_q: 2.031243, mean_eps: 0.631000\n",
            "  101/9000: episode: 7, duration: 0.127s, episode steps:  12, steps per second:  94, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.750 [0.000, 1.000],  loss: 0.046733, mae: 1.106296, mean_q: 2.104931, mean_eps: 0.574750\n",
            "  112/9000: episode: 8, duration: 0.116s, episode steps:  11, steps per second:  95, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.818 [0.000, 1.000],  loss: 0.051381, mae: 1.166837, mean_q: 2.243314, mean_eps: 0.523000\n",
            "  125/9000: episode: 9, duration: 0.134s, episode steps:  13, steps per second:  97, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.846 [0.000, 1.000],  loss: 0.060795, mae: 1.195219, mean_q: 2.344420, mean_eps: 0.469000\n",
            "  138/9000: episode: 10, duration: 0.140s, episode steps:  13, steps per second:  93, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.615 [0.000, 1.000],  loss: 0.063271, mae: 1.294656, mean_q: 2.453245, mean_eps: 0.410500\n",
            "  150/9000: episode: 11, duration: 0.129s, episode steps:  12, steps per second:  93, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 0.055547, mae: 1.307607, mean_q: 2.584670, mean_eps: 0.354250\n",
            "  160/9000: episode: 12, duration: 0.114s, episode steps:  10, steps per second:  88, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: 0.067377, mae: 1.383133, mean_q: 2.658695, mean_eps: 0.304750\n",
            "  170/9000: episode: 13, duration: 0.105s, episode steps:  10, steps per second:  95, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: 0.073960, mae: 1.446407, mean_q: 2.827333, mean_eps: 0.259750\n",
            "  188/9000: episode: 14, duration: 0.205s, episode steps:  18, steps per second:  88, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.222 [0.000, 1.000],  loss: 0.097338, mae: 1.528072, mean_q: 2.886618, mean_eps: 0.196750\n",
            "  202/9000: episode: 15, duration: 0.158s, episode steps:  14, steps per second:  89, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.714 [0.000, 1.000],  loss: 0.079256, mae: 1.594327, mean_q: 3.114373, mean_eps: 0.125071\n",
            "  214/9000: episode: 16, duration: 0.130s, episode steps:  12, steps per second:  92, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.833 [0.000, 1.000],  loss: 0.140683, mae: 1.635553, mean_q: 3.151427, mean_eps: 0.100000\n",
            "  226/9000: episode: 17, duration: 0.130s, episode steps:  12, steps per second:  92, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.917 [0.000, 1.000],  loss: 0.265500, mae: 1.761096, mean_q: 3.273323, mean_eps: 0.100000\n",
            "  235/9000: episode: 18, duration: 0.109s, episode steps:   9, steps per second:  83, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.778 [0.000, 1.000],  loss: 0.182721, mae: 1.755654, mean_q: 3.235923, mean_eps: 0.100000\n",
            "  247/9000: episode: 19, duration: 0.133s, episode steps:  12, steps per second:  90, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.917 [0.000, 1.000],  loss: 0.129861, mae: 1.767022, mean_q: 3.353447, mean_eps: 0.100000\n",
            "  256/9000: episode: 20, duration: 0.102s, episode steps:   9, steps per second:  88, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.889 [0.000, 1.000],  loss: 0.134075, mae: 1.815926, mean_q: 3.497604, mean_eps: 0.100000\n",
            "  283/9000: episode: 21, duration: 0.287s, episode steps:  27, steps per second:  94, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.741 [0.000, 1.000],  loss: 0.122276, mae: 1.866107, mean_q: 3.535809, mean_eps: 0.100000\n",
            "  292/9000: episode: 22, duration: 0.095s, episode steps:   9, steps per second:  94, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: 0.118909, mae: 1.941266, mean_q: 3.680986, mean_eps: 0.100000\n",
            "  302/9000: episode: 23, duration: 0.105s, episode steps:  10, steps per second:  95, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.900 [0.000, 1.000],  loss: 0.108208, mae: 2.006323, mean_q: 3.801478, mean_eps: 0.100000\n",
            "  311/9000: episode: 24, duration: 0.099s, episode steps:   9, steps per second:  91, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.889 [0.000, 1.000],  loss: 0.175498, mae: 1.945683, mean_q: 3.756192, mean_eps: 0.100000\n",
            "  328/9000: episode: 25, duration: 0.179s, episode steps:  17, steps per second:  95, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.412 [0.000, 1.000],  loss: 0.144297, mae: 2.114149, mean_q: 3.959769, mean_eps: 0.100000\n",
            "  340/9000: episode: 26, duration: 0.124s, episode steps:  12, steps per second:  97, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.750 [0.000, 1.000],  loss: 0.205671, mae: 2.094721, mean_q: 3.997486, mean_eps: 0.100000\n",
            "  374/9000: episode: 27, duration: 0.353s, episode steps:  34, steps per second:  96, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 0.145042, mae: 2.228752, mean_q: 4.219925, mean_eps: 0.100000\n",
            "  421/9000: episode: 28, duration: 0.474s, episode steps:  47, steps per second:  99, episode reward: 47.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.596 [0.000, 1.000],  loss: 0.201042, mae: 2.337849, mean_q: 4.474765, mean_eps: 0.100000\n",
            "  438/9000: episode: 29, duration: 0.168s, episode steps:  17, steps per second: 101, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 0.226777, mae: 2.411887, mean_q: 4.556170, mean_eps: 0.100000\n",
            "  447/9000: episode: 30, duration: 0.107s, episode steps:   9, steps per second:  84, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.222 [0.000, 1.000],  loss: 0.390474, mae: 2.685627, mean_q: 5.083953, mean_eps: 0.100000\n",
            "  456/9000: episode: 31, duration: 0.096s, episode steps:   9, steps per second:  94, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 0.411512, mae: 2.456172, mean_q: 4.687182, mean_eps: 0.100000\n",
            "  536/9000: episode: 32, duration: 0.810s, episode steps:  80, steps per second:  99, episode reward: 80.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.613 [0.000, 1.000],  loss: 0.343731, mae: 2.739430, mean_q: 5.245932, mean_eps: 0.100000\n",
            "  558/9000: episode: 33, duration: 0.224s, episode steps:  22, steps per second:  98, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.364 [0.000, 1.000],  loss: 0.202724, mae: 2.951236, mean_q: 5.687657, mean_eps: 0.100000\n",
            "  583/9000: episode: 34, duration: 0.262s, episode steps:  25, steps per second:  96, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 0.286623, mae: 3.068500, mean_q: 5.833687, mean_eps: 0.100000\n",
            "  607/9000: episode: 35, duration: 0.240s, episode steps:  24, steps per second: 100, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.458217, mae: 3.154276, mean_q: 5.995412, mean_eps: 0.100000\n",
            "  616/9000: episode: 36, duration: 0.098s, episode steps:   9, steps per second:  91, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.222 [0.000, 1.000],  loss: 0.730300, mae: 3.359973, mean_q: 6.242940, mean_eps: 0.100000\n",
            "  637/9000: episode: 37, duration: 0.215s, episode steps:  21, steps per second:  98, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 0.690803, mae: 3.388690, mean_q: 6.199199, mean_eps: 0.100000\n",
            "  654/9000: episode: 38, duration: 0.176s, episode steps:  17, steps per second:  97, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.294 [0.000, 1.000],  loss: 0.333867, mae: 3.439488, mean_q: 6.566836, mean_eps: 0.100000\n",
            "  681/9000: episode: 39, duration: 0.289s, episode steps:  27, steps per second:  94, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.222 [0.000, 1.000],  loss: 0.314363, mae: 3.411693, mean_q: 6.558733, mean_eps: 0.100000\n",
            "  708/9000: episode: 40, duration: 0.267s, episode steps:  27, steps per second: 101, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 0.400617, mae: 3.539747, mean_q: 6.676485, mean_eps: 0.100000\n",
            "  731/9000: episode: 41, duration: 0.237s, episode steps:  23, steps per second:  97, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.391 [0.000, 1.000],  loss: 0.491562, mae: 3.689770, mean_q: 6.917608, mean_eps: 0.100000\n",
            "  800/9000: episode: 42, duration: 0.694s, episode steps:  69, steps per second:  99, episode reward: 69.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.406 [0.000, 1.000],  loss: 0.475589, mae: 3.853751, mean_q: 7.428327, mean_eps: 0.100000\n",
            "  847/9000: episode: 43, duration: 0.466s, episode steps:  47, steps per second: 101, episode reward: 47.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.468 [0.000, 1.000],  loss: 0.453889, mae: 4.086979, mean_q: 7.831126, mean_eps: 0.100000\n",
            "  857/9000: episode: 44, duration: 0.106s, episode steps:  10, steps per second:  94, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 0.612888, mae: 4.263044, mean_q: 8.088284, mean_eps: 0.100000\n",
            "  873/9000: episode: 45, duration: 0.178s, episode steps:  16, steps per second:  90, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.250 [0.000, 1.000],  loss: 0.572183, mae: 4.290921, mean_q: 8.227946, mean_eps: 0.100000\n",
            "  899/9000: episode: 46, duration: 0.258s, episode steps:  26, steps per second: 101, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.604928, mae: 4.336286, mean_q: 8.195134, mean_eps: 0.100000\n",
            "  911/9000: episode: 47, duration: 0.132s, episode steps:  12, steps per second:  91, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 0.281443, mae: 4.411492, mean_q: 8.642185, mean_eps: 0.100000\n",
            "  926/9000: episode: 48, duration: 0.160s, episode steps:  15, steps per second:  94, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 0.499591, mae: 4.410998, mean_q: 8.543763, mean_eps: 0.100000\n",
            "  944/9000: episode: 49, duration: 0.188s, episode steps:  18, steps per second:  96, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.415041, mae: 4.491611, mean_q: 8.793640, mean_eps: 0.100000\n",
            "  960/9000: episode: 50, duration: 0.184s, episode steps:  16, steps per second:  87, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: 0.556232, mae: 4.605072, mean_q: 8.790629, mean_eps: 0.100000\n",
            " 1005/9000: episode: 51, duration: 0.451s, episode steps:  45, steps per second: 100, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 0.602727, mae: 4.753903, mean_q: 9.137790, mean_eps: 0.100000\n",
            " 1034/9000: episode: 52, duration: 0.319s, episode steps:  29, steps per second:  91, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.483 [0.000, 1.000],  loss: 0.680042, mae: 4.934789, mean_q: 9.492977, mean_eps: 0.100000\n",
            " 1065/9000: episode: 53, duration: 0.340s, episode steps:  31, steps per second:  91, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.484 [0.000, 1.000],  loss: 0.885397, mae: 5.057896, mean_q: 9.716529, mean_eps: 0.100000\n",
            " 1080/9000: episode: 54, duration: 0.165s, episode steps:  15, steps per second:  91, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.133 [0.000, 1.000],  loss: 1.004498, mae: 5.259086, mean_q: 10.027781, mean_eps: 0.100000\n",
            " 1106/9000: episode: 55, duration: 0.262s, episode steps:  26, steps per second:  99, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 0.934025, mae: 5.231640, mean_q: 10.034983, mean_eps: 0.100000\n",
            " 1130/9000: episode: 56, duration: 0.255s, episode steps:  24, steps per second:  94, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.542 [0.000, 1.000],  loss: 0.672386, mae: 5.354351, mean_q: 10.261952, mean_eps: 0.100000\n",
            " 1146/9000: episode: 57, duration: 0.165s, episode steps:  16, steps per second:  97, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.312 [0.000, 1.000],  loss: 1.104152, mae: 5.425809, mean_q: 10.472275, mean_eps: 0.100000\n",
            " 1175/9000: episode: 58, duration: 0.298s, episode steps:  29, steps per second:  97, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.483 [0.000, 1.000],  loss: 0.904252, mae: 5.587226, mean_q: 10.815924, mean_eps: 0.100000\n",
            " 1303/9000: episode: 59, duration: 1.246s, episode steps: 128, steps per second: 103, episode reward: 128.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.523 [0.000, 1.000],  loss: 0.908787, mae: 5.771034, mean_q: 11.108004, mean_eps: 0.100000\n",
            " 1377/9000: episode: 60, duration: 0.736s, episode steps:  74, steps per second: 101, episode reward: 74.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.473 [0.000, 1.000],  loss: 1.040523, mae: 6.194470, mean_q: 11.972771, mean_eps: 0.100000\n",
            " 1408/9000: episode: 61, duration: 0.312s, episode steps:  31, steps per second:  99, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.484 [0.000, 1.000],  loss: 1.188140, mae: 6.430456, mean_q: 12.499699, mean_eps: 0.100000\n",
            " 1502/9000: episode: 62, duration: 0.948s, episode steps:  94, steps per second:  99, episode reward: 94.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.532 [0.000, 1.000],  loss: 1.267595, mae: 6.665803, mean_q: 12.846242, mean_eps: 0.100000\n",
            " 1666/9000: episode: 63, duration: 1.651s, episode steps: 164, steps per second:  99, episode reward: 164.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 1.222327, mae: 7.172145, mean_q: 13.918505, mean_eps: 0.100000\n",
            " 1686/9000: episode: 64, duration: 0.204s, episode steps:  20, steps per second:  98, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.450 [0.000, 1.000],  loss: 1.639929, mae: 7.490672, mean_q: 14.357151, mean_eps: 0.100000\n",
            " 1715/9000: episode: 65, duration: 0.300s, episode steps:  29, steps per second:  97, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 1.563940, mae: 7.521275, mean_q: 14.520965, mean_eps: 0.100000\n",
            " 1803/9000: episode: 66, duration: 0.873s, episode steps:  88, steps per second: 101, episode reward: 88.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.477 [0.000, 1.000],  loss: 1.286383, mae: 7.823166, mean_q: 15.234293, mean_eps: 0.100000\n",
            " 2003/9000: episode: 67, duration: 1.957s, episode steps: 200, steps per second: 102, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 1.490757, mae: 8.394103, mean_q: 16.357439, mean_eps: 0.100000\n",
            " 2162/9000: episode: 68, duration: 1.535s, episode steps: 159, steps per second: 104, episode reward: 159.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.535 [0.000, 1.000],  loss: 1.927424, mae: 9.210865, mean_q: 17.920659, mean_eps: 0.100000\n",
            " 2333/9000: episode: 69, duration: 1.713s, episode steps: 171, steps per second: 100, episode reward: 171.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.503 [0.000, 1.000],  loss: 2.115828, mae: 9.892336, mean_q: 19.248083, mean_eps: 0.100000\n",
            " 2452/9000: episode: 70, duration: 1.183s, episode steps: 119, steps per second: 101, episode reward: 119.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.504 [0.000, 1.000],  loss: 2.242125, mae: 10.482740, mean_q: 20.392397, mean_eps: 0.100000\n",
            " 2638/9000: episode: 71, duration: 1.813s, episode steps: 186, steps per second: 103, episode reward: 186.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.527 [0.000, 1.000],  loss: 2.545456, mae: 11.044517, mean_q: 21.501605, mean_eps: 0.100000\n",
            " 2838/9000: episode: 72, duration: 1.953s, episode steps: 200, steps per second: 102, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.530 [0.000, 1.000],  loss: 2.366324, mae: 11.750125, mean_q: 23.016555, mean_eps: 0.100000\n",
            " 2990/9000: episode: 73, duration: 1.503s, episode steps: 152, steps per second: 101, episode reward: 152.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.507 [0.000, 1.000],  loss: 3.125644, mae: 12.465587, mean_q: 24.201188, mean_eps: 0.100000\n",
            " 3190/9000: episode: 74, duration: 2.001s, episode steps: 200, steps per second: 100, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 3.302432, mae: 13.071325, mean_q: 25.531088, mean_eps: 0.100000\n",
            " 3388/9000: episode: 75, duration: 1.983s, episode steps: 198, steps per second: 100, episode reward: 198.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.530 [0.000, 1.000],  loss: 3.384927, mae: 13.879587, mean_q: 27.025353, mean_eps: 0.100000\n",
            " 3550/9000: episode: 76, duration: 1.584s, episode steps: 162, steps per second: 102, episode reward: 162.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.512 [0.000, 1.000],  loss: 3.528357, mae: 14.523017, mean_q: 28.406029, mean_eps: 0.100000\n",
            " 3737/9000: episode: 77, duration: 1.826s, episode steps: 187, steps per second: 102, episode reward: 187.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.503 [0.000, 1.000],  loss: 3.278529, mae: 15.088011, mean_q: 29.790866, mean_eps: 0.100000\n",
            " 3937/9000: episode: 78, duration: 2.083s, episode steps: 200, steps per second:  96, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 3.928324, mae: 15.869071, mean_q: 31.102278, mean_eps: 0.100000\n",
            " 4137/9000: episode: 79, duration: 2.088s, episode steps: 200, steps per second:  96, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 4.500172, mae: 16.663163, mean_q: 32.683979, mean_eps: 0.100000\n",
            " 4337/9000: episode: 80, duration: 1.970s, episode steps: 200, steps per second: 102, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 4.359581, mae: 17.327316, mean_q: 34.249194, mean_eps: 0.100000\n",
            " 4533/9000: episode: 81, duration: 1.918s, episode steps: 196, steps per second: 102, episode reward: 196.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 4.828729, mae: 18.181260, mean_q: 35.818537, mean_eps: 0.100000\n",
            " 4733/9000: episode: 82, duration: 1.956s, episode steps: 200, steps per second: 102, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 5.392711, mae: 18.779746, mean_q: 37.124020, mean_eps: 0.100000\n",
            " 4933/9000: episode: 83, duration: 2.016s, episode steps: 200, steps per second:  99, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 4.954835, mae: 19.467651, mean_q: 38.732868, mean_eps: 0.100000\n",
            " 5115/9000: episode: 84, duration: 1.791s, episode steps: 182, steps per second: 102, episode reward: 182.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 4.673292, mae: 20.246795, mean_q: 40.554238, mean_eps: 0.100000\n",
            " 5297/9000: episode: 85, duration: 1.842s, episode steps: 182, steps per second:  99, episode reward: 182.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 5.619327, mae: 20.853437, mean_q: 41.420777, mean_eps: 0.100000\n",
            " 5460/9000: episode: 86, duration: 1.648s, episode steps: 163, steps per second:  99, episode reward: 163.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.528 [0.000, 1.000],  loss: 6.597959, mae: 21.568462, mean_q: 42.834633, mean_eps: 0.100000\n",
            " 5660/9000: episode: 87, duration: 2.988s, episode steps: 200, steps per second:  67, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 5.595413, mae: 21.972967, mean_q: 43.884197, mean_eps: 0.100000\n",
            " 5804/9000: episode: 88, duration: 1.413s, episode steps: 144, steps per second: 102, episode reward: 144.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 6.239799, mae: 22.659674, mean_q: 45.288572, mean_eps: 0.100000\n",
            " 5944/9000: episode: 89, duration: 1.365s, episode steps: 140, steps per second: 103, episode reward: 140.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.514 [0.000, 1.000],  loss: 6.139265, mae: 23.196689, mean_q: 46.151878, mean_eps: 0.100000\n",
            " 6136/9000: episode: 90, duration: 1.856s, episode steps: 192, steps per second: 103, episode reward: 192.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.521 [0.000, 1.000],  loss: 7.068596, mae: 23.732347, mean_q: 47.170753, mean_eps: 0.100000\n",
            " 6303/9000: episode: 91, duration: 1.640s, episode steps: 167, steps per second: 102, episode reward: 167.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.521 [0.000, 1.000],  loss: 5.979647, mae: 24.238734, mean_q: 48.448817, mean_eps: 0.100000\n",
            " 6455/9000: episode: 92, duration: 1.488s, episode steps: 152, steps per second: 102, episode reward: 152.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.487 [0.000, 1.000],  loss: 7.241613, mae: 24.785988, mean_q: 49.264407, mean_eps: 0.100000\n",
            " 6655/9000: episode: 93, duration: 1.915s, episode steps: 200, steps per second: 104, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 6.838097, mae: 25.192157, mean_q: 50.217154, mean_eps: 0.100000\n",
            " 6762/9000: episode: 94, duration: 1.072s, episode steps: 107, steps per second: 100, episode reward: 107.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 7.202778, mae: 25.642723, mean_q: 51.055595, mean_eps: 0.100000\n",
            " 6955/9000: episode: 95, duration: 1.853s, episode steps: 193, steps per second: 104, episode reward: 193.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.518 [0.000, 1.000],  loss: 6.090698, mae: 26.125340, mean_q: 52.268090, mean_eps: 0.100000\n",
            " 7119/9000: episode: 96, duration: 1.618s, episode steps: 164, steps per second: 101, episode reward: 164.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 6.377691, mae: 26.720966, mean_q: 53.241402, mean_eps: 0.100000\n",
            " 7319/9000: episode: 97, duration: 1.943s, episode steps: 200, steps per second: 103, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 7.782086, mae: 27.246201, mean_q: 54.251014, mean_eps: 0.100000\n",
            " 7498/9000: episode: 98, duration: 1.760s, episode steps: 179, steps per second: 102, episode reward: 179.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 8.537318, mae: 27.559404, mean_q: 54.809441, mean_eps: 0.100000\n",
            " 7682/9000: episode: 99, duration: 1.816s, episode steps: 184, steps per second: 101, episode reward: 184.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 7.817721, mae: 27.802680, mean_q: 55.517419, mean_eps: 0.100000\n",
            " 7766/9000: episode: 100, duration: 0.823s, episode steps:  84, steps per second: 102, episode reward: 84.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.464 [0.000, 1.000],  loss: 6.804651, mae: 28.299127, mean_q: 56.555113, mean_eps: 0.100000\n",
            " 7831/9000: episode: 101, duration: 0.648s, episode steps:  65, steps per second: 100, episode reward: 65.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.477 [0.000, 1.000],  loss: 6.904548, mae: 28.318835, mean_q: 56.749986, mean_eps: 0.100000\n",
            " 8031/9000: episode: 102, duration: 1.983s, episode steps: 200, steps per second: 101, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 6.493039, mae: 28.750022, mean_q: 57.389491, mean_eps: 0.100000\n",
            " 8197/9000: episode: 103, duration: 1.647s, episode steps: 166, steps per second: 101, episode reward: 166.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 9.264915, mae: 29.308804, mean_q: 58.210239, mean_eps: 0.100000\n",
            " 8397/9000: episode: 104, duration: 2.050s, episode steps: 200, steps per second:  98, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 6.953359, mae: 29.510497, mean_q: 58.975704, mean_eps: 0.100000\n",
            " 8582/9000: episode: 105, duration: 1.824s, episode steps: 185, steps per second: 101, episode reward: 185.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 6.743566, mae: 30.100985, mean_q: 60.120896, mean_eps: 0.100000\n",
            " 8760/9000: episode: 106, duration: 1.756s, episode steps: 178, steps per second: 101, episode reward: 178.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.528 [0.000, 1.000],  loss: 8.211919, mae: 30.352346, mean_q: 60.448105, mean_eps: 0.100000\n",
            " 8960/9000: episode: 107, duration: 1.990s, episode steps: 200, steps per second: 100, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 7.188664, mae: 30.643526, mean_q: 61.323437, mean_eps: 0.100000\n",
            " 8979/9000: episode: 108, duration: 0.207s, episode steps:  19, steps per second:  92, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.368 [0.000, 1.000],  loss: 8.272068, mae: 31.716905, mean_q: 63.334836, mean_eps: 0.100000\n",
            "done, took 96.417 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n",
            "Episode 6: reward: 200.000, steps: 200\n",
            "Episode 7: reward: 200.000, steps: 200\n",
            "Episode 8: reward: 200.000, steps: 200\n",
            "Episode 9: reward: 200.000, steps: 200\n",
            "Episode 10: reward: 200.000, steps: 200\n",
            "Episode 11: reward: 200.000, steps: 200\n",
            "Episode 12: reward: 200.000, steps: 200\n",
            "Episode 13: reward: 200.000, steps: 200\n",
            "Episode 14: reward: 200.000, steps: 200\n",
            "Episode 15: reward: 200.000, steps: 200\n",
            "Episode 16: reward: 200.000, steps: 200\n",
            "Episode 17: reward: 200.000, steps: 200\n",
            "Episode 18: reward: 200.000, steps: 200\n",
            "Episode 19: reward: 200.000, steps: 200\n",
            "Episode 20: reward: 200.000, steps: 200\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5d3749c610>"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    }
  ]
}